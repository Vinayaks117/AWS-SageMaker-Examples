{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Supercharge BERT Inference with AWS Inferentia2 and Hugging Face Transformers\n",
    "\n",
    "In this end-to-end tutorial, we will learn how to speed up BERT inference for text classification with Hugging Face Transformers, Amazon SageMaker, and AWS Inferentia2.\n",
    "\n",
    "We will learn how to:\n",
    "\n",
    "1. Convert your Hugging Face Transformer to AWS Neuron (Inferentia2)\n",
    "2. Create a custom `inference.py` script for `text-classification`\n",
    "3. Create and upload the neuron model and inference script to Amazon S3\n",
    "4. Deploy a Real-time Inference Endpoint on Amazon SageMaker\n",
    "5. Run and evaluate Inference performance of BERT on Inferentia2\n",
    "6. Clean Up\n",
    "\n",
    "Let's get started! ðŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1. Convert your Hugging Face Transformer to AWS Neuron\n",
    "\n",
    "Need to create an EC2 instance using the following parameters.\n",
    "- `Instance type = ml.inf2.xlarge` has single inf2 accelerator with 4 CPU cores.\n",
    "- `AMI = HuggingFace DL AMI(Ubuntu 20.04)` which makes it easy to use Amazon EC2 Inferentia & Trainium instances for efficient training and inference of Hugging Face Transformers and Diffusers models.\n",
    "\n",
    "Then we can leverage the HuggingFace Optimum Neuron to export a model to Neuron using the export function.\n",
    "We first need to install some extra dependencies:\n",
    "`pip install optimum[neuronx]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = 'model/'\n",
    "code_path = 'code/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from optimum.exporters.neuron import export\n",
    "from optimum.exporters.neuron.model_configs import DistilBertNeuronConfig\n",
    "\n",
    "model_id = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id)\n",
    "neuron_config = DistilBertNeuronConfig(\n",
    "    config=model.config, task=\"text-classification\", batch_size=1, sequence_length=128,\n",
    ")\n",
    "\n",
    "# save tokenizer, neuron model and config for later use\n",
    "save_dir = \"test_bert\"\n",
    "\n",
    "# export to Neuron model\n",
    "export(\n",
    "    model=model,\n",
    "    config=neuron_config,\n",
    "    output=(os.path.join(save_dir,\"model.neuron\")),\n",
    "    auto_cast=\"none\",\n",
    "    auto_cast_type=\"tf32\",\n",
    ")\n",
    "\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "model.config.save_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use either SageMaker notebook instance or SageMaker Studio to deploy the Neuron model on a Real-time endpoint.\n",
    "\n",
    "Then can download the neuron model and tokenizer config files from the above step and store them in the model directory, e.g `model/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"distilbert-base-uncased-finetuned-sst-2-english\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2. Create a custom `inference.py` script for `text-classification`\n",
    "\n",
    "We need to create an `inference.py` script by overwriting the `model_fn` to load our neuron model and the `predict_fn` to create a text-classification pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir {model_path}/code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using the NEURON_RT_NUM_CORES=1 to make sure that each HTTP worker uses 1 Neuron core to maximize throughput."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/inference.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "from transformers import AutoConfig, AutoTokenizer\n",
    "\n",
    "# To use one neuron core per worker\n",
    "os.environ[\"NEURON_RT_NUM_CORES\"] = \"1\"\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"\n",
    "    Load the model for inference\n",
    "    \"\"\"   \n",
    "    # Load tokenizer and neuron model from model_dir\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "    neuron_model = torch.jit.load(os.path.join(model_dir, \"model.neuron\"))\n",
    "    model_config = AutoConfig.from_pretrained(model_dir)\n",
    "    model_dict = {'neuron_model': neuron_model, 'tokenizer': tokenizer, 'model_config': model_config}\n",
    "    \n",
    "    return model_dict\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    \"\"\"Apply model to the incoming request.\n",
    "    \n",
    "    Documents \n",
    "    \"\"\"\n",
    "    tokenizer = model['tokenizer']\n",
    "    neuron_model = model['neuron_model']\n",
    "    model_config = model['model_config']\n",
    "\n",
    "    sequence = input_data[\"sequence\"]\n",
    "\n",
    "    embeddings = tokenizer(\n",
    "        sequence,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=128,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "    )\n",
    "    \n",
    "    # convert to tuple for neuron model\n",
    "    neuron_inputs = tuple(embeddings.values())\n",
    "    \n",
    "    # run prediciton\n",
    "    with torch.no_grad():\n",
    "        predictions = neuron_model(*neuron_inputs)[0]\n",
    "        scores = torch.nn.Softmax(dim=1)(predictions)\n",
    "\n",
    "    # return dictonary, which will be json serializable\n",
    "    return [{\"label\": model_config.id2label[item.argmax().item()], \"score\": item.max().item()} for item in scores]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3. Create and upload the neuron model and inference script to Amazon S3\n",
    "\n",
    "For hosting, SageMaker requires that the deployment package be structured in a compatible format. It expects all files to be packaged in a tar archive named `model.tar.gz` with gzip compression.\n",
    "\n",
    "We need to create a `model.tar.gz` archive with all our model artifacts saved into `model/`, e.g. `model.neuron` and upload this to Amazon S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "    \n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create our `model.tar.gz`. The inference.py script will be placed into a `code/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./\n",
      "./tokenizer_config.json\n",
      "./.ipynb_checkpoints/\n",
      "./model.neuron\n",
      "./config.json\n",
      "./special_tokens_map.json\n",
      "./vocab.txt\n",
      "./model.tar.gz\n",
      "tar: ./model.tar.gz: file changed as we read it\n",
      "./tokenizer.json\n",
      "./code/\n",
      "./code/.ipynb_checkpoints/\n",
      "./code/.ipynb_checkpoints/inference-checkpoint.py\n",
      "./code/inference.py\n",
      "tar: .: file changed as we read it\n"
     ]
    }
   ],
   "source": [
    "# copy inference.py into the code/ directory of the model directory.\n",
    "!cp code/inference.py {model_path}/code/inference.py\n",
    "\n",
    "# create a model.tar.gz archive with all the model artifacts and the inference.py script.\n",
    "!tar -czvf {model_path}/model.tar.gz -C {model_path}/ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can upload our model.tar.gz to our session S3 bucket with sagemaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "# create s3 uri\n",
    "s3_model_path = f\"s3://{sess.default_bucket()}/{model_id}\"\n",
    "\n",
    "# upload model.tar.gz\n",
    "s3_model_uri = S3Uploader.upload(local_path=\"model/model.tar.gz\",desired_s3_uri=s3_model_path)\n",
    "print(f\"model artifcats uploaded to {s3_model_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 4. Deploy a Real-time Inference Endpoint on Amazon SageMaker\n",
    "\n",
    "After we upload model.tar.gz to S3, we can deploy our endpoint. We will use boto3 API to create and deploy our real-time inference endpoint on Amazon SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create/Register a BERT model in SM\n",
    "image_uri = \"763104351884.dkr.ecr.us-east-2.amazonaws.com/huggingface-pytorch-inference-neuronx:1.13.0-transformers4.28.1-neuronx-py38-sdk2.9.1-ubuntu20.04\"\n",
    "deployment_name = \"text-classification\"\n",
    "\n",
    "primary_container = {\n",
    "    'Image': image_uri,\n",
    "    'ModelDataUrl': s3_model_uri,\n",
    "    'Environment': {\n",
    "        'SAGEMAKER_PROGRAM': 'inference.py',\n",
    "        'SAGEMAKER_REGION': sess.boto_region_name,\n",
    "        'SAGEMAKER_SUBMIT_DIRECTORY': s3_model_uri,\n",
    "        'SAGEMAKER_MODEL_SERVER_WORKERS': '2'\n",
    "    }\n",
    "}\n",
    "\n",
    "create_model_response = sm_client.create_model(ModelName = f\"{deployment_name}-model\",\n",
    "                                              ExecutionRoleArn = get_execution_role(),\n",
    "                                              PrimaryContainer = primary_container)\n",
    "\n",
    "print(create_model_response['ModelArn'])\n",
    "\n",
    "# create SageMaker Endpoint configuration\n",
    "endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName = f\"{deployment_name}-epc\",\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "        'InstanceType':'ml.inf2.xlarge',\n",
    "        'InitialInstanceCount':1,\n",
    "        'ModelName': f\"{deployment_name}-model\",\n",
    "        'VariantName':'AllTraffic',\n",
    "        'InitialVariantWeight':1\n",
    "        }\n",
    "    ])\n",
    "\n",
    "print('Endpoint configuration arn:  {}'.format(endpoint_config_response['EndpointConfigArn']))\n",
    "\n",
    "# create SageMaker Endpoint\n",
    "endpoint_params = {\n",
    "    'EndpointName': f\"{deployment_name}-ep\", 'EndpointConfigName': f\"{deployment_name}-epc\"}\n",
    "endpoint_response = sm_client.create_endpoint(**endpoint_params)\n",
    "print('EndpointArn = {}'.format(endpoint_response['EndpointArn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 5. Run and evaluate Inference performance of BERT on Inferentia2\n",
    "\n",
    "Now that our API endpoint is deployed, we can send it text to get predictions from our BERT model. We can use the SageMaker Runtime API to invoke the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "sm = boto3.client('sagemaker-runtime')\n",
    "endpoint_name = f\"{deployment_name}-ep\"\n",
    "payload = {\"sequence\": \"Hello, my cats are cute.\"}\n",
    "payload = json.dumps(payload)\n",
    "\n",
    "response = sm.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                              Body=payload,\n",
    "                              ContentType='application/json')\n",
    "\n",
    "result = json.loads(response['Body'].read())\n",
    "print(\"response:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "response: [{'label': 'POSITIVE', 'score': 0.9998264908790588}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We managed to deploy our neuron-compiled BERT to AWS Inferentia2 on Amazon SageMaker. Now, let's test its performance of it. As a dummy load test will we loop and send 10000 synchronous requests to our endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# send 10000 requests\n",
    "for i in range(10000):\n",
    "    response = sm.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                Body=payload,\n",
    "                                ContentType='application/json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the performance in Cloudwatch and we can see that the average latency for our BERT model is 2-3ms for a sequence length of 128."
   ]
  },
  {
   "attachments": {
    "924ded85-ad7d-49c5-9010-63e9da3496b6.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:924ded85-ad7d-49c5-9010-63e9da3496b6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Clean Up\n",
    "\n",
    "To clean up, we can delete the model and endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client.delete_model(ModelName=f\"{deployment_name}-model\")\n",
    "sm_client.delete_endpoint_config(EndpointConfigName=f\"{deployment_name}-epc\")\n",
    "sm_client.delete_endpoint(EndpointName=f\"{deployment_name}-ep\")"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "c8dfa52194188e48d6802840b718748a7140cbefa937517cab1c2b201bcac497"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
